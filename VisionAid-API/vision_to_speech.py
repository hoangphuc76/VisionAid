"""
VisionAid - Vision to Speech API
Simple and powerful API for converting images to speech, designed to help visually impaired people
access visual information through audio.
"""
import os
import time
import requests
from typing import Optional, Dict, Any
from google import genai
from google.genai import types
from elevenlabs.client import ElevenLabs
from config import get_config


class VTS:
    """
    VisionAid Vision to Speech - Convert images to audio files
    
    A simple yet powerful API that converts images to MP3 audio files,
    specifically designed to help visually impaired people access visual information.
    
    Features:
    - Smart image analysis using Google Gemini Flash Lite
    - Natural Vietnamese text-to-speech using ElevenLabs
    - OCR for documents and contextual description for scenes
    """
    
    def __init__(self, gemini_api_key: Optional[str] = None, elevenlabs_api_key: Optional[str] = None, voice_id: Optional[str] = None):
        """
        Initialize VTS with API keys
        
        Args:
            gemini_api_key (str, optional): Google Gemini API key (loads from .env if not provided)
            elevenlabs_api_key (str, optional): ElevenLabs API key (loads from .env if not provided)
            voice_id (str, optional): ElevenLabs voice ID (loads from .env if not provided, default: George - multilingual)
        """
        # Load config if keys not provided
        config = get_config()
        
        self.gemini_client = genai.Client(api_key=gemini_api_key or config.gemini_api_key)
        self.eleven_client = ElevenLabs(api_key=elevenlabs_api_key or config.elevenlabs_api_key)
        self.voice_id = voice_id or config.default_voice_id
        self.model = "gemini-2.5-flash-lite"
        
        print(f"[DEBUG] ElevenLabs API Key: {elevenlabs_api_key or config.elevenlabs_api_key}")

        # Enhanced prompt with danger detection
        self.prompt = """
Nhi·ªám v·ª•:
1. Ph√¢n lo·∫°i ·∫£nh th√†nh m·ªôt trong ba lo·∫°i:
   - [T√†i li·ªáu]: N·∫øu b·ª©c ·∫£nh l√† t√†i li·ªáu/trang gi·∫•y ‚Üí OCR to√†n b·ªô n·ªôi dung v√† format l·∫°i ho√†n ch·ªânh, kh√¥ng t√≥m t·∫Øt.
   - [Ng·ªØ c·∫£nh]: N·∫øu b·ª©c ·∫£nh l√† c·∫£nh v·∫≠t/b·ªëi c·∫£nh ‚Üí m√¥ t·∫£ t·ªïng th·ªÉ b·∫±ng ti·∫øng Vi·ªát t·ª± nhi√™n.
   - [H√≥a ƒë∆°n]: N·∫øu b·ª©c ·∫£nh l√† h√≥a ƒë∆°n/phi·∫øu thanh to√°n ‚Üí tr√≠ch xu·∫•t th√¥ng tin (t√™n c·ª≠a h√†ng, ng√†y, m·∫∑t h√†ng, gi√°, t·ªïng ti·ªÅn).
2. N·∫øu th·ªÉ lo·∫°i l√† [Ng·ªØ c·∫£nh], h√£y ki·ªÉm tra v·∫≠t th·ªÉ nguy hi·ªÉm (l·ª≠a, dao, xe ƒëang ch·∫°y, h·ªë s√¢u...):
   - N·∫øu c√≥ ‚Üí th√™m d√≤ng "‚ö†Ô∏è C·∫£nh b√°o: ..." ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu.
   - N·∫øu kh√¥ng ‚Üí ghi "Kh√¥ng ph√°t hi·ªán nguy hi·ªÉm."
Format tr·∫£ k·∫øt qu·∫£:
Th·ªÉ lo·∫°i: [T√†i li·ªáu | H√≥a ƒë∆°n | Ng·ªØ c·∫£nh]
N·ªôi dung: <n·ªôi dung t∆∞∆°ng ·ª©ng>
"""
            
    def convert(self, image_path: str, output_mp3_path: str) -> Dict[str, Any]:
        """
        Convert image to speech MP3 file
        
        Args:
            image_path (str): Path to input image file
            output_mp3_path (str): Path for output MP3 file
            
        Returns:
            Dict with success status and details
        """
        try:
            # Step 1: Check if image exists
            if not os.path.exists(image_path):
                return {
                    "success": False,
                    "error": f"File kh√¥ng t·ªìn t·∫°i: {image_path}",
                    "text_result": None,
                    "audio_path": None
                }
            
            print("üîç ƒêang ph√¢n t√≠ch ·∫£nh v·ªõi Gemini Flash Lite...")
            
            # Step 2: Read image and send to Gemini
            with open(image_path, "rb") as f:
                image_bytes = f.read()
            
            response = self.gemini_client.models.generate_content(
                model=self.model,
                contents=[
                    types.Part.from_bytes(data=image_bytes, mime_type="image/jpeg"),
                    self.prompt
                ]
            )
            
            text_result = response.text.strip()
            print(f"üìÑ K·∫øt qu·∫£ ph√¢n t√≠ch (100 k√Ω t·ª± ƒë·∫ßu): {text_result[:100]}...")
            
            # Step 3: Convert text to speech with ElevenLabs
            print("üîä ƒêang chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i...")
            
            audio_stream = self.eleven_client.text_to_speech.convert(
                text=text_result,
                voice_id=self.voice_id,
                model_id="eleven_flash_v2_5",
                output_format="mp3_44100_128",
            )
            
            # Step 4: Save MP3 file
            output_dir = os.path.dirname(output_mp3_path)
            if output_dir:  # Only create directory if output_dir is not empty
                os.makedirs(output_dir, exist_ok=True)
            with open(output_mp3_path, "wb") as f:
                for chunk in audio_stream:
                    f.write(chunk)
            
            print(f"‚úÖ ƒê√£ l∆∞u file √¢m thanh t·∫°i: {output_mp3_path}")
            
            return {
                "success": True,
                "error": None,
                "text_result": text_result,
                "audio_path": output_mp3_path,
                "voice_id": self.voice_id
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "text_result": None,
                "audio_path": None
            }
    
    def set_voice(self, voice_id: str):
        """Change ElevenLabs voice ID"""
        self.voice_id = voice_id
    
    def set_prompt(self, prompt: str):
        """Change analysis prompt"""
        self.prompt = prompt


# Example usage:
if __name__ == "__main__":
    # Option 1: Auto-load from .env file (recommended)
    vts = VTS()
    
    # Option 2: Provide keys explicitly
    # vts = VTS(
    #     gemini_api_key="YOUR_GEMINI_API_KEY", 
    #     elevenlabs_api_key="YOUR_ELEVENLABS_API_KEY",
    #     voice_id="JBFqnCBsd6RMkjVDRZzb"
    # )
    
    # Convert image to speech
    result = vts.convert(
        image_path="path/to/your/image.jpg",
        output_mp3_path="output.mp3"
    )
    
    if result["success"]:
        print("‚úÖ Ho√†n t·∫•t chuy·ªÉn ƒë·ªïi!")
        print(f"üìÑ VƒÉn b·∫£n: {result['text_result']}")
        print(f"üîä File √¢m thanh: {result['audio_path']}")
    else:
        print(f"‚ùå L·ªói: {result['error']}")